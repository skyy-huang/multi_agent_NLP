# 多智能体学术写作优化系统 

> 主题：学术表达优化助手。系统包含两个智能体：Agent A 负责修改优化草稿，Agent B 负责严格审查并给出结构化评分与建议，二者多轮往复后输出最终结果；同时支持数据合成、蒸馏与 LoRA 微调原型。

---
## 目录
1. 项目简介
2. 核心功能与特性
3. **🌟 Web图形化界面** (新增)
4. 代码结构说明
5. 环境准备与安装
6. 配置说明（.env / 环境变量）
7. 快速上手：常用命令示例
8. CLI 参数与工作流详情
9. Jupyter Notebook 与脚本的一致性说明
10. 典型使用场景与优化思路
11. 数据格式规范（合成 / 蒸馏 / 报告）
12. 评估指标含义
13. 性能与调优建议
14. 常见问题 FAQ
15. 后续扩展建议

---
## 1. 项目简介
本项目实现了一个针对“学术风格文本优化”的多智能体闭环系统：
- **Agent A（Optimizer）**：根据用户需求与历史记忆对文本进行多轮学术化改写；
- **Agent B（Reviewer）**：对 Agent A 的输出进行结构化评估与打分，指出剩余问题并给出下一轮改进建议；
- 通过多轮 A/B 协作，逐步收敛到质量更高的版本，并记录完整的协作日志、评分、差异（Diff）、工具调用观测等信息。

系统还提供：
- **数据合成（synthesize）**：从种子文本出发，批量生成多轮协作数据（含 teacher signal 与评分）；
- **蒸馏数据构造（distill）**：从合成数据中抽取 `instruction/output` 训练对；
- **LoRA / QLoRA 微调脚本（lora_distill.py）**：将蒸馏对用于小模型微调；
- **评估模式（eval）**：对多条文本运行多轮优化并计算一系列轻量指标与 Agent B 评分均值；
- **HTML / JSON 报告**：可视化展示每一轮的文本、Diff、评分与工具调用信息。

该项目适合用于：
- 学术写作场景原型验证；
- prompt 与多智能体协作策略实验；
- 生成蒸馏数据并微调较小的中文/英文语言模型。

---
## 2. 核心功能与特性
- **多轮双 Agent 协作**：`--rounds` 控制轮数，每轮包含一次 Agent A 改写与一次 Agent B 评审；
- **ReAct 风格工具调用**：在满足特定条件时触发网络搜索（SerpAPI）、Python REPL、文件读写等工具；
- **向量记忆 / 召回**：优先使用 FAISS + Embeddings（若依赖或 Key 缺失则回退到简单字符串相似度检索）；
- **健壮的回退链**：LLM / Embeddings / VectorStore / Search 多层回退，保证即使没有 API Key 也能跑通流程（使用 DummyLLM 占位输出）；
- **长文本分段优化**：支持从文件读取长文，按句子智能分段并带重叠区域进行多轮优化，再将各段拼接为整体；
- **数据合成与蒸馏链路**：从多轮协作日志生成适合指令微调的 `instruction/output` 蒸馏对；
- **评估指标**：自动计算长度变化、词汇多样性、重复度下降、可读性、连贯性、句长方差变化、双元组重复变化等指标，并聚合均值；
- **报告生成**：输出结构化 JSON 以及带 Diff 高亮的 HTML 报告，方便分析与展示。

---
## 3. 🌟 Web图形化界面 (新增)

为了提供更直观、易用的操作体验，项目新增了现代化的Web图形界面，支持所有核心功能的可视化操作。

### 🎨 界面特性
- **现代化设计**: Bootstrap 5 + 自定义样式，响应式布局
- **实时进度**: WebSocket实时显示优化进度和状态
- **多模式支持**: 文本输入模式 + 文件上传模式
- **可视化配置**: 图形化参数设置和API配置管理
- **多格式导出**: 支持文本、HTML报告、JSON数据下载

### 🚀 快速启动Web界面

```bash
# 1. 进入Web界面目录
cd web_interface

# 2. 安装Web依赖
pip install -r requirements_web.txt

# 3. 启动Web服务
python start_web.py

# 4. 访问界面
# 浏览器打开: http://localhost:5000
```

### 📋 主要功能模块

#### 📝 文本优化模块
- **文本输入**: 直接输入要优化的学术文本
- **文件上传**: 支持长文件分段处理(.txt, .md等格式)
- **实时监控**: 实时显示优化进度、状态和日志
- **结果展示**: 对比视图、最终结果、轮次详情三种查看模式
- **评分可视化**: 质量、严谨性、逻辑、新颖性等维度评分图表

#### 🔬 数据合成模块
- **种子文本输入**: 支持多行种子文本批量处理
- **参数配置**: 可设置合成需求、轮次等参数
- **进度跟踪**: 实时显示合成进度和状态

#### 📊 评估分析模块
- **测试用例管理**: 支持格式化测试用例输入
- **多维评估**: 自动运行多维度性能评估
- **指标可视化**: 图表展示各项评估指标

#### ⚗️ 数据蒸馏模块
- **文件处理**: 上传JSONL文件进行蒸馏处理
- **格式转换**: 自动生成监督学习训练对
- **结果下载**: 支持蒸馏后数据下载

#### ⚙️ 配置管理
- **API配置**: 可视化设置OpenAI API Key、Base URL等
- **参数调优**: 图形化调整优化参数
- **配置保存**: 自动保存常用配置到浏览器本地

### 🌐 API接口说明

Web界面提供完整的RESTful API，支持程序化调用：

```bash
# 文本优化
POST /api/optimize/text
POST /api/optimize/file

# 数据处理  
POST /api/synthesize
POST /api/evaluate
POST /api/distill

# 任务管理
GET /api/task/<task_id>

# 结果下载
GET /api/download/<task_id>/text
GET /api/download/<task_id>/html  
GET /api/download/<task_id>/json
```

### 🎯 使用建议

1. **首次使用**: 在配置页面设置API密钥和相关参数
2. **短文本**: 直接使用文本输入模式
3. **长文档**: 使用文件上传模式，合理设置分段参数
4. **批量处理**: 使用数据合成功能生成大量训练数据
5. **性能分析**: 使用评估模块测试不同配置的效果

### 📁 目录结构
```
web_interface/
├── app.py              # Flask后端应用
├── start_web.py        # 启动脚本  
├── demo.py            # 演示脚本
├── index.html         # 主页面
├── requirements_web.txt # Web依赖
├── static/
│   ├── css/styles.css # 样式文件
│   └── js/app.js      # 前端逻辑
└── README.md          # Web界面详细说明
```

详细使用说明请参考 `web_interface/README.md`。

---
## 4. 代码结构说明
- `multi_agent_nlp_project.py`：
  - 整个系统的主入口脚本；
  - 定义 LLM 初始化与回退逻辑、工具集合、向量记忆、双 Agent 协作系统 `DualAgentAcademicSystem`；
  - 提供命令行接口（demo / synthesize / eval / distill），以及长文本分段优化逻辑；
  - 提供 JSON / HTML 报告生成与写入辅助函数。
- `multi_agent_nlp_project.ipynb`：
  - 与脚本逻辑严格同步的 Notebook 版本；
  - 以章节划分方式呈现环境检查、LLM 初始化、工具层、向量记忆、双 Agent 协作、示例调用等；
  - 适合交互试验与可视化展示；如需参考实现细节，可在 Notebook 中逐格查看对应于脚本的实现片段。
- `lora_distill.py`：
  - 使用 Hugging Face Transformers + PEFT + Datasets 对蒸馏对进行 LoRA / QLoRA 微调；
  - 支持普通 LoRA 与 4bit QLoRA（当安装 `bitsandbytes` 且 `--qlora` 打开时）；
  - 输出微调后的权重与训练配置说明 `RUN_INFO.txt`。
- `requirements.txt`：
  - 项目的 Python 依赖清单，覆盖 LangChain、OpenAI 客户端、检索、微调相关库；
- `.env.example`：
  - 环境变量示例配置文件，可复制为 `.env` 并填入自己的 API Key 与服务地址。

---
## 4. 环境准备与安装
### 4.1 Python 版本
建议使用 Python 3.10 及以上版本。

### 4.2 创建虚拟环境（Windows CMD）
```bat
cd D:\Projects\PythonProject\multi_agent_NLP
python -m venv .venv
.venv\Scripts\activate
python -m pip install --upgrade pip
pip install -r requirements.txt
copy .env.example .env
```

Linux / macOS 示例：
```bash
cd /path/to/multi_agent_NLP
python -m venv .venv
source .venv/bin/activate
python -m pip install --upgrade pip
pip install -r requirements.txt
cp .env.example .env
```

---
## 5. 配置说明（.env / 环境变量）
在项目根目录创建 `.env` 文件（可从 `.env.example` 复制）：
```ini
OPENAI_API_KEY=你的OpenAI或兼容接口Key（可选）
SERPAPI_API_KEY=你的SerpAPI Key（可选）
OPENAI_BASE_URL=https://api.deepseek.com        # 或其他 OpenAI 兼容接口
LLM_MODEL=deepseek-reasoner                     # 如 gpt-4o-mini / deepseek-chat 等
EMBED_MODEL_NAME=text-embedding-3-small         # 当 Base URL 支持 embeddings 时生效
ENABLE_INTERACTIVE=0                            # 1 开启交互模式，0 关闭
```
说明：
- 未配置 `OPENAI_API_KEY` 时，系统自动使用 `DummyLLM`，输出为占位文本，仅用于调试流程；
- 当 `OPENAI_BASE_URL` 包含 `deepseek.com` 且 `LLM_MODEL` 非官方推荐名字时，脚本会自动规范为 `deepseek-chat` 或 `deepseek-reasoner`；
- 未配置 `SERPAPI_API_KEY` 时，网络搜索工具会以占位实现替代，但接口仍然可调用。

---
## 6. 快速上手：常用命令示例
以下示例假定你已在虚拟环境中并配置好 `.env`。

### 6.1 单条中文文本多轮优化（Demo）
```bat
python multi_agent_nlp_project.py demo
```

自定义文本与需求：
```bat
python multi_agent_nlp_project.py demo ^
  --rounds 3 ^
  --text "这是一段关于多智能体协作进行学术写作优化的初稿。" ^
  --requirements "学术表达提升;逻辑结构优化" ^
  --report demo.json ^
  --html-report demo.html
```

英文模式示例：
```bat
python multi_agent_nlp_project.py demo ^
  --lang en ^
  --text "This is a rough draft about multi-agent collaboration for academic writing." ^
  --requirements "academic polish,logical coherence" ^
  --report demo_en.json ^
  --html-report demo_en.html
```

### 6.2 长文本文件优化
将待优化的论文草稿保存为 `paper_draft.txt`：
```bat
python multi_agent_nlp_project.py demo ^
  --text-file paper_draft.txt ^
  --rounds 2 ^
  --requirements "学术表达提升,结构清晰" ^
  --chunk-size 5000 ^
  --chunk-overlap 200 ^
  --out-text-file optimized_paper.txt ^
  --report long_demo.json ^
  --html-report long_demo.html
```

### 6.3 数据合成 → 蒸馏 → LoRA 微调
1. 合成多轮协作数据：
```bat
python multi_agent_nlp_project.py synthesize ^
  --rounds 3 ^
  --requirements "学术表达提升,结构清晰,可读性增强" ^
  --out data\synth.jsonl
```

2. 构造蒸馏训练对：
```bat
python multi_agent_nlp_project.py distill ^
  --distill-src data\synth.jsonl ^
  --distill-out data\distill_pairs.jsonl
```

3. 使用 `lora_distill.py` 进行 LoRA 微调：
```bat
python lora_distill.py ^
  --data data\distill_pairs.jsonl ^
  --model qwen/Qwen1.5-0.5B ^
  --output runs\qwen-mini-lora ^
  --epochs 1 ^
  --batch 2 ^
  --fp16
```

如需 QLoRA 4bit（需 GPU 与 `bitsandbytes`）：
```bat
python lora_distill.py ^
  --data data\distill_pairs.jsonl ^
  --model qwen/Qwen1.5-1.8B-Chat ^
  --output runs\qwen-lora-4bit ^
  --epochs 1 ^
  --batch 2 ^
  --qlora ^
  --fp16
```

### 6.4 评估模式
```bat
python multi_agent_nlp_project.py eval ^
  --rounds 2 ^
  --requirements "严谨性,逻辑连贯" ^
  --report eval.json ^
  --html-report eval.html
```

控制台会输出类似：
```text
📈 评估汇总: {"len_gain_avg":0.132,"ttr_gain_avg":0.045,"repetition_delta_avg":0.021,"n":2,...}
```

### 6.5 禁用部分组件做消融实验
```bat
python multi_agent_nlp_project.py demo ^
  --rounds 2 ^
  --no-tools ^
  --no-memory
```
这会关闭工具调用和向量记忆，便于对比多智能体策略本身的贡献。

---
## 7. CLI 参数与工作流详情
脚本入口：`multi_agent_nlp_project.py`，总体调用方式：
```text
python multi_agent_nlp_project.py [command] [--options]
```

### 7.1 command 子命令
- `demo`：单条文本多轮优化（支持长文本分段、报告输出）；
- `synthesize`：基于种子文本批量合成多轮协作数据，写入 JSONL；
- `eval`：对多条测试文本运行协作流程，统计多维指标；
- `distill`：从合成的 JSONL 数据中生成蒸馏训练对 JSONL。

### 7.2 通用参数
- `--rounds <int>`：协作轮次（>=1）；
- `--requirements <str>`：用逗号/分号/中文分号分隔的需求列表；
- `--lang zh|en`：语言（会影响默认初稿与默认需求）；
- `--no-tools`：禁用工具调用层；
- `--no-memory`：禁用向量记忆层；
- `--report <path>`：输出 JSON 报告（demo / eval / synthesize / distill 不同模式下结构略有不同）；
- `--html-report <path>`：输出 HTML 可视化报告（demo / eval / 长文本 demo 支持）。

### 7.3 demo 模式特有参数
- `--text <str>`：直接在命令行提供初始文本；
- `--text-file <path>`：从文本文件读取长初稿并自动分段；
- `--chunk-size <int>`：单段最大字符数（默认 5000，<=0 表示不分段）；
- `--chunk-overlap <int>`：相邻分段的重叠字符数（默认 200，用于保持上下文连贯性）；
- `--max-chunks <int>`：限制最多处理的段数（0 表示不限制，仅用于快速实验）；
- `--out-text-file <path>`：将最终优化后的整篇文本写入该路径。

### 7.4 synthesize / distill 特有参数
- `--seeds-file <path>`（synthesize）：从文件读取种子文本（每行一条）。未提供时使用内置 3 条示例；
- `--out <path>`（synthesize）：指定合成 JSONL 输出路径；
- `--distill-src <path>`（distill）：上游合成 JSONL 源；
- `--distill-out <path>`（distill）：蒸馏对 JSONL 输出路径。

---
## 8. Notebook 与脚本的一致性说明
- `multi_agent_nlp_project.ipynb` 与 `multi_agent_nlp_project.py` 在核心逻辑上保持同步：
  - LLM 初始化与三层回退策略；
  - 工具层构造（SerpAPI / Python REPL / 文件读写）；
  - 向量记忆（FAISS 或 SimpleVectorStore 回退）；
  - 双 Agent 协作系统 `DualAgentAcademicSystem`（prompt 设计、评分解析、Diff 计算）；
- Notebook 以“章节 + 代码单元”的形式展开上述实现，方便逐步执行和可视化调试；
- 当你在脚本中修改核心逻辑时，建议同步更新 Notebook 中对应单元，以保持示例与实际行为一致（当前仓库已完成一次同步校验）。

在 Notebook 中进行一次端到端示例：
1. 运行环境检查与 LLM 初始化单元；
2. 运行工具层与向量记忆单元；
3. 实例化 `DualAgentAcademicSystem`：
   ```python
   system = DualAgentAcademicSystem(llm, TOOLS, vectorstore)
   ```
4. 调用多轮协作：
   ```python
   final_text, log = system.collaborate(
       "这是一段关于多智能体协作进行学术写作优化的初稿。",
       ["学术表达提升", "逻辑结构优化"],
       rounds=2,
   )
   ```
5. 根据 `log` 中的 `scores`、`diff`、`tool_observations` 进一步分析每一轮表现。

---
## 9. 典型使用场景与优化思路
- **学术论文段落打磨**：将 Methods/Results/Discussion 段落依次送入系统，根据“严谨性”“逻辑连贯”“可读性”等需求进行多轮优化；
- **数据生成与蒸馏**：使用较强的商业模型（如 GPT-4 级别）进行多轮协作，生成高质量 teacher signal，再对开源模型、企业私有模型做蒸馏微调；
- **多智能体策略实验**：基于本框架尝试不同的 Agent 角色、评分维度、工具触发逻辑，观察其对最终文本质量与指标的影响；
- **长篇报告 / 毕业论文草稿润色**：利用 `--text-file` + 分段重叠设计，处理较长的中文/英文学术文档，并输出整体优化结果与分段日志。

---
## 11. 🆕 高级学术指标系统

项目新增了一套全面的学术文本质量评价指标，可自动计算并评估优化前后的改进。

### 11.1 完整的评价指标列表

| 指标 | 说明 | 范围 |
|------|------|------|
| **学术规范性** (academic_formality) | 检查学术词汇使用、短语规范，评估文本学术化程度 | 0-1 |
| **引用完整性** (citation_completeness) | 评估引用格式、引用密度、论据充分性 | 0-1 |
| **创新度** (novelty) | 检测新颖表述、突破性观点、方法创新标记词 | 0-1 |
| **语言流畅度** (language_fluency) | 基于改进的阅读难度指数（Flesch 中文版） | 0-1 |
| **句子复杂度平衡** (sentence_complexity_balance) | 检测句长分布、变异系数，避免全长或全短 | 0-1 |
| **论证强度** (argumentation_strength) | 评估前提、论据、结论的完整性与逻辑关联 | 0-1 |
| **表达多样性** (expression_diversity) | 词汇多样性 (TTR)、句式多样性、避免重复 | 0-1 |
| **结构完整性** (structure_completeness) | 检测引言、主体、结论、局限讨论等部分 | 0-1 |
| **时态一致性** (tense_consistency) | 检测过去式/现在式使用的一致性 | 0-1 |
| **综合评分** (overall_score) | 所有指标的加权平均 (可自定义权重) | 0-1 |

### 11.2 改进指标

除了单项评分外，系统还计算了优化前后的改进幅度：

- `*_improvement`：各维度的改进差值（正值表示改进）
- `overall_improvement`：总体质量的改进幅度
- `improvement_rate`：改进百分比

### 11.3 使用新指标评估

#### 方式1：直接在 eval 模式中使用
```bash
python multi_agent_nlp_project.py eval \
  --rounds 2 \
  --report eval_with_metrics.json \
  --html-report eval_with_metrics.html
```

生成的报告将包含：
- 基础文本指标汇总表
- Agent B 评分汇总
- 高级学术指标卡片（带改进箭头和进度条）

#### 方式2：在 Python 代码中使用
```python
from metrics import AcademicMetrics

# 计算单个文本的所有指标
text = "你的学术文本..."
result = AcademicMetrics.overall_quality_score(text)

# 查看所有指标
print(result['scores'])  # 单项评分
print(result['overall_score'])  # 综合评分

# 对比优化前后的改进
original = "原始文本..."
optimized = "优化文本..."
comparison = AcademicMetrics.compare_improvements(original, optimized)

for metric, improvement in comparison['metric_improvements'].items():
    print(f"{metric}: {improvement:+.4f}")
```

#### 方式3：快速评估脚本
```bash
python -c "from metrics import quick_evaluate; quick_evaluate('你的文本...')"
```

输出将显示：
```
============================================================
学术文本质量评估报告
============================================================

文本统计:
  字数: 150
  句数: 5
  段数: 2

各维度评分 (0-1):
  Academic Formality       0.7850 [████████████████░░░░]
  Citation Completeness    0.5200 [██████████░░░░░░░░░░]
  Novelty                  0.4500 [█████████░░░░░░░░░░░]
  Language Fluency         0.8200 [████████████████░░░░]
  ...

整体综合评分: 0.6520
============================================================
```

### 11.4 HTML 报告中的指标可视化

新的 HTML 报告包含以下可视化元素：

- **指标卡片网格**：展示每个改进维度的改进幅度，用颜色和箭头表示正/负改进
- **进度条**：直观显示改进强度
- **颜色编码**：
  - 🟢 绿色：正向改进
  - 🔴 红色：负向改进
  - ⬜ 灰色：无明显变化

### 11.5 自定义权重

可以自定义各指标的权重：

```python
from metrics import AcademicMetrics

custom_weights = {
    'academic_formality': 0.20,      # 提高学术规范权重
    'citation_completeness': 0.15,   # 强调引用完整性
    'novelty': 0.10,
    'language_fluency': 0.12,
    'sentence_balance': 0.08,
    'argumentation': 0.15,
    'expression_diversity': 0.08,
    'structure_completeness': 0.10,
    'tense_consistency': 0.02
}

result = AcademicMetrics.overall_quality_score(text, weights=custom_weights)
```

### 11.6 指标应用场景

| 场景 | 推荐指标 | 权重调整 |
|------|----------|---------|
| 学术论文 | 全部 | 提高学术规范、引用完整性 |
| 技术文档 | 除新颖性外 | 提高结构完整性、流畅度 |
| 创新论文 | 全部 | 提高新颖性、论证强度 |
| 综述文章 | 全部 | 提高结构、引用完整性 |
| 网络文章 | 流畅度、多样性 | 降低学术规范权重 |

---
## 12. 数据格式规范
### 12.1 合成数据（synthesize 输出 JSONL）
每行一个 JSON 对象，示例结构：
```json
{
  "id": "case_0",
  "input": "原始种子文本",
  "requirements": ["学术表达提升", "结构清晰"],
  "final": "最终优化文本",
  "log": [
    {"round": 0, "user_input": "...", "requirements": ["..."], "timestamp": "..."},
    {"round": 1, "optimized_text": "...", "agent_b_feedback": "...", "scores": {"quality": 8.0, "rigor": 7.0}, "diff": "...", ...},
    {"round": 2, ...}
  ],
  "created_at": "ISO 时间",
  "teacher_signal": "最后一轮 optimized_text（用于蒸馏）",
  "scores": {"quality": 8.0, "rigor": 7.0, "logic": 7.0, "novelty": 6.0}
}
```

### 12.2 蒸馏对（distill 输出 JSONL）
```json
{"instruction": "优化以下学术段落，满足需求: 学术表达提升, 结构清晰\n原文: ...", "output": "teacher 信号文本", "scores": {"quality":8.0,"rigor":7.0}}
```

### 12.3 LoRA 训练拼接格式
`lora_distill.py` 会将每条 `instruction/output` 拼接为：
```text
指令:
<instruction>

优质答案:
<output>
```
用于常规自回归语言模型微调。

### 12.4 报告 JSON / HTML
- JSON 报告（`--report`）：
  - demo 模式：`{"final": 最终文本, "log": 协作日志}`；
  - 长文本模式：`{"final": 最终整篇文本, "aggregated": {"segments": [...], ...}}`；
  - eval 模式：`{"summary": 指标均值, "cases": 单条样本指标}` **（现已包含高级学术指标）**；
  - synthesize / distill 模式：包含生成文件路径等元信息。
- HTML 报告（`--html-report`）：
  - 按轮展示优化文本、Agent B 反馈、评分、Diff（新内容高亮为绿色，删除为红色）、工具调用观测；
  - eval 模式下展示指标汇总表格与各案例的概览 **（新增高级学术指标卡片、进度条、改进可视化）**；
  - 支持响应式布局和暗色主题支持。

---
## 13. 评估指标含义

### 13.1 基础文本指标

| 指标 | 说明 |
|------|------|
| `len_gain` | 长度变化比例 `(final_len - orig_len) / orig_len` |
| `ttr_gain` | 词汇多样性 Type Token Ratio 提升 |
| `repetition_delta` | 最高频 token 占比下降（越大越少重复） |
| `readability_gain` | 基于平均句长的可读性代理值变化 |
| `coherence_gain` | 邻接句子词汇交集/并集比平均提升，作为连贯性代理 |
| `sent_var_delta` | 原句长方差 - 新句长方差（正值表示更均匀） |
| `bigram_rep_delta` | 高频二元组占比下降（重复模式减少） |
| `quality/rigor/logic/novelty` | Agent B 在 JSON 中给出的主观评分均值 |

### 13.2 高级学术指标

| 指标 | 说明 | 示例 |
|------|------|------|
| `academic_formality_improvement` | 学术规范性提升 | +0.15 表示学术表达更规范 |
| `citation_completeness_improvement` | 引用完整性提升 | +0.12 表示论据更充分 |
| `novelty_improvement` | 创新度提升 | +0.08 表示更具突破性 |
| `language_fluency_improvement` | 语言流畅度提升 | +0.10 表示更易阅读 |
| `sentence_balance_improvement` | 句子复杂度平衡度提升 | +0.05 表示句长分布更合理 |
| `argumentation_improvement` | 论证强度提升 | +0.12 表示逻辑论证更完整 |
| `expression_diversity_improvement` | 表达多样性提升 | +0.08 表示词汇更丰富 |
| `structure_completeness_improvement` | 结构完整性提升 | +0.10 表示段落划分更清晰 |
| `tense_consistency_improvement` | 时态一致性提升 | +0.03 表示时态使用更统一 |
| `overall_improvement` | 综合质量提升 | +0.09 表示总体质量提升9% |

这些指标由 `DualAgentAcademicSystem.evaluate()` 和 `AcademicMetrics.compare_improvements()` 计算并在 eval 模式中聚合输出。

---
## 14. 性能与调优建议
| 目标 | 建议 |
|------|------|
| 提升速度 | 降低 `--rounds`、缩短初稿、在不关键场景下关闭工具与记忆（`--no-tools --no-memory`） |
| 降低显存占用 | 使用 QLoRA 4bit（`--qlora`），减小 `--max-length`，调低 batch 或使用梯度累积 |
| 强化多样性 | 在合成阶段丰富需求组合与种子语料、多语言混合、增加轮数 |
| 提升 teacher 质量 | 使用更强的上游大模型生成合成数据，再对开源模型、企业私有模型做蒸馏 |
| 减少指令截断 | 在 `lora_distill.py` 中适当提高 `--max-length`（需平衡显存） |
| 训练更平稳 | 增大 `--epochs`、设置合理的 `--warmup-ratio`、按数据规模调整 `--gradient-accum` |

---
## 15. 常见问题 FAQ
1. **导入 faiss 失败？**  
   - 已自动回退到 `SimpleVectorStore`，功能仍可使用；如需更高召回质量与性能，可安装 `faiss-cpu`。

2. **搜索结果总是占位？**  
   - 很可能没有设置 `SERPAPI_API_KEY`，可在 `.env` 中补充或忽略搜索相关功能。

3. **输出看起来总是“空话”？**  
   - 检查是否未设置 `OPENAI_API_KEY`，此时使用的是 `DummyLLM` 占位输出，仅用于调试；配置真实 Key 后重新运行。

4. **Embeddings 初始化失败或 404？**  
   - 部分兼容接口（如 DeepSeek）暂不支持 embeddings，本项目会自动切换到 `DummyEmbeddings` 与简易向量检索，不影响主流程。

5. **bitsandbytes 安装失败？**  
   - 不使用 `--qlora` 即可，只跑普通 LoRA；或在支持的 GPU/驱动环境中安装 `bitsandbytes`。

6. **HTML 报告没有生成？**  
   - 仅 demo / eval / 长文本模式会生成 HTML 报告，`synthesize` 与 `distill` 仅输出 JSON 或 JSONL 文件。

7. **Agent B 的评分 JSON 解析失败？**  
   - 可能是模型未严格遵循 JSON 格式提示；可以提高模型质量、增加约束提示，或在后处理时增加更鲁棒的解析方式。

8. **Diff 太长或不易阅读？**  
   - 内部对 Diff 有 400 行的截断逻辑，可根据需要在 `DualAgentAcademicSystem._compute_diff` 中调整。

---
## 16. 后续扩展建议
- 在 `_plan_and_act()` 中新增领域检索工具（如论文数据库 API），增强事实依据；
- 扩展 Agent B 的评分维度与诊断模板，例如增加“清晰度”“严谨引用”“实验完整性”等；
- 引入并行分段处理与跨段全局精修，进一步提升长文档整体一致性；
- 将目前的指标与日志输出接入可视化面板（如 Streamlit / Gradio）构建交互 Demo UI。

本 README 与 `multi_agent_nlp_project.py` / `multi_agent_nlp_project.ipynb` 已按当前代码同步整理，可作为理解和使用整个“学术表达优化助手”项目的主参考文档。
